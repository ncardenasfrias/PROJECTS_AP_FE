install.packages("Quandl")
library(Quandl)
mydate = Quandl("FRED/GDP")
View(mydate)
View(mydate)
mydata = Quandl("FRED/GDP", type="ts")
View(mydata)
mydata
print(mydata)
mydata
q()
pacman::p_load(data.table, tseries, reshape2, smoots, dplyr, bootUR, urca, gridExtra, tidyverse, gplots, xts, stargazer, forecast, ggplot2, vars)
setwd('/Users/nataliacardenasf/Documents/GitHub/PROJECTS_AP_FE/FinancialEconometrics1')
###########################
#0. Preprocessing
###########################
#Load the dataset, data gathering and cleaning done in Python
df = fread("DATA/data.csv")
as.data.table(df)
#change few names of columns to got something more clear
names(df)[1] = 'Date'
#Apply log to variables for which it makes sense ie prices and quantities
df$sp500 = log(df$sp500) #get the stock market return
df$splong = log(df$splong)
df$corp_debt = log(df$corp_debt) #return corporate debt (see index definition)
df$gdp = log(df$gdp)
df$rpi  = log(df$rpi)
df$dpi  = log(df$dpi)
#convert into TS
allts = list()
numeric_cols = df[, sapply(df, is.numeric)&names(df)!= 'Date'] #identifies the right columns
for(col in names(numeric_cols)){
allts[[col]] = ts(df[[col]], start= c(year(df$Date[1]), month(df$Date[1])), frequency=12)
}
allts[['sp500']] = NULL #remove short SP500, use YahooFinance series that has the 90's and 00's data
allts[['Date']] = NULL # R was making regressions on the date column :/
#remove columns we ended up not using in the final version
allts[['manufacturing']] = NULL # rather not have data that was initially yearly
allts[['rpi']] = NULL # redundent with dpi
allts[['unempl']] = NULL # did not lead anywhere
allts[['corp_debt']] = NULL # we end up not using it and the UR test are weird
#Reorganise the list
desired_order = c('gdp', 'dpi', 'infl_e', 'deflator', 'rate', 'splong')
allts = allts[desired_order]
names = c('GDP', "Disposable Income", 'Inflation expectation', 'PIB deflator', 'Fed rate', 'SP500')
#Remove outliers => IT DOES NOT CHANGE ANYTHING
# tsclean(allts$infl_e, iterate = 2, lambda =NULL)
# tsclean(allts$deflator, iterate = 2, lambda =NULL)
# tsclean(allts$unempl, iterate = 2, lambda =NULL)
# tsclean(allts$rate, iterate = 2, lambda =NULL)
# tsclean(allts$splong, iterate = 2, lambda =NULL)
# tsclean(allts$corp_debt, iterate = 2, lambda =NULL)
df$sp500 = NULL
df$corp_debt = NULL
df$unempl = NULL
df$rpi = NULL
df$manufacturing = NULL
desired_order = c("Date", desired_order)
df <- df[, ..desired_order]
df_long <- melt(df, id.vars = "Date")
deltas = list (diff(allts$gdp), diff(allts$dpi),
diff(allts$rate),diff(allts$splong))
names(deltas) = list("d_gdp","d_dpi","d_rate", "d_splong")
#Get df with all the I(1) series in levels
levels_var = data.frame(
gdp = allts$gdp,
dpi = allts$dpi,
rate = allts$rate,
splong = allts$splong)
start_date = as.Date("1990-01-01")
end_date = as.Date("2022-12-01") # Assuming December 2022
all_dates = seq(start_date, end_date, by = "month")
levels_var$date = all_dates
rownames(levels_var) = levels_var$date #date as index
levels_var$date = NULL
lag_order = VARselect(levels_var)
res = lag_order$criteria
johansen_test = ca.jo(levels_var, type='trace', ecdet='trend', K=10)
jo_sum = summary(johansen_test)
# r is rank of matrix == number of cointegration relationship.
#no cointegration
johansen_table = xtable::xtable(summary(johansen_test))
diff_var_data = data.frame(splong = deltas$d_splong, gdp =deltas$d_gdp, rate = deltas$d_rate)
# Identify the order of the VAR model
var_order <- VARselect(diff_var_data, lag.max = 10, type = "both")#$selection
res = var_order$criteria
crit_level = as.data.frame(res)
rownames(crit_level) = c("AIC(n)", "HQ(n)", "SC(n)", "FPE(n)")
latex_varorder_lev= xtable(crit_level, caption = "Canonical VAR in levels - Identify order")
print(latex_varorder_lev, caption.placement = "top", include.rownames = TRUE, file = "TABLES/varorder_level.tex")
latex_varorder_lev
latex_varorder_lev= xtable(crit_level, caption = "Canonical VAR in levels - Identify order")
# Load necessary packages and set personal path to documents
pacman::p_load(data.table, xtable, tseries, reshape2, smoots, dplyr, bootUR, urca, gridExtra, tidyverse, gplots, xts, stargazer, forecast, ggplot2, vars)
latex_varorder_lev= xtable(crit_level, caption = "Canonical VAR in levels - Identify order")
latex_varorder_lev
print(var_order$selection)
# Estimate the VAR model
var_model1 <- VAR(diff_var_data, p = 7, type = "both")
sum_varlevel = summary(var_model1)$varresult
stargazer(var_model1[['varresult']], type='text')
# Impulse Response Analysis for var_model1 from Empirical Analysis 2 + its graph
irf_var_model1 <- irf(var_model1, n.ahead = 10, boot = TRUE, ci = 0.95, cumulative=T)
plot(irf_var_model1)
causality_gdp_splong <- causality(var_model, cause = "gdp", test = "ssr")
levels_var = data.frame(
gdp = allts$gdp,
#dpi = allts$dpi,
rate = allts$rate,
splong = allts$splong)
start_date = as.Date("1990-01-01")
end_date = as.Date("2022-12-01") # Assuming December 2022
all_dates = seq(start_date, end_date, by = "month")
levels_var$date = all_dates
rownames(levels_var) = levels_var$date #date as index
levels_var$date = NULL
lag_order = VARselect(levels_var)
res = lag_order$criteria
johansen_test = ca.jo(levels_var, type='trace', ecdet='trend', K=10)
jo_sum = summary(johansen_test)
jo_sum
jo_sum
johansen_test = ca.jo(levels_var, type='eigen', ecdet='trend', K=10)
jo_sum = summary(johansen_test)
jo_sum
print(causality_gdp$Granger)
causality_gdp <- causality(var_model1, cause = "gdp")
print(causality_gdp$Granger)
# Causality test between SPLong and GDP
causality_splong <- causality(var_model1, cause = "splong")
print(causality_splong$Granger)
# Causality test between SPLong and Federal Reserve Rate
causality_rate <- causality(var_model1, cause = "rate")
print(causality_rate$Granger)
